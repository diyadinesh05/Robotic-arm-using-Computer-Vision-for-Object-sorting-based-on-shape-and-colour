<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Project Report</title>

  <style>
    html {
  scroll-behavior: smooth;
}

body {
  margin: 0;
  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
  background-color: #ffffff;
  color: #333;
  line-height: 1.6;
}

header {
  background: linear-gradient(90deg, #6fa3ef, #4e8ef7);
  color: #fff;
  padding: 2rem 1rem;
  text-align: center;
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
}

header h1 {
  margin: 0;
  font-size: 2.5rem;
}

header p {
  font-size: 1.2rem;
  margin-top: 0.5rem;
}

nav {
  background-color: #2b71b7;
  display: flex;
  flex-wrap: wrap;
  justify-content: center;
  gap: 1rem;
  padding: 1rem;
}

nav button {
  background-color: #4e8ef7;
  color: #fff;
  border: none;
  border-radius: 4px;
  padding: 0.6rem 1.5rem;
  font-weight: 600;
  cursor: pointer;
  transition: background-color 0.3s ease, transform 0.2s;
}

nav button:hover {
  background-color: #357ab7;
  transform: scale(1.05);
}

main {
  max-width: 1000px;
  margin: auto;
  padding: 2rem 1rem;
}

section {
  background-color: #ffffff;
  border-radius: 12px;
  padding: 2rem;
  margin-bottom: 2rem;
  box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
  border-left: 5px solid #6fa3ef;
}

h2 {
  color: #2b71b7;
  border-bottom: 3px solid #6fa3ef;
  padding-bottom: 0.5rem;
  font-size: 1.8rem;
}

h3, h4 {
  color: #333;
}

ul {
  padding-left: 1.5rem;
}

li {
  margin-bottom: 0.8rem;
}

table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 1rem;
}

th, td {
  border: 1px solid #ccc;
  padding: 0.8rem;
  text-align: left;
}

th {
  background-color: #2b71b7;
  color: #fff;
}

tr:nth-child(even) {
  background-color: #f9f9f9;
}

code {
  background-color: #f4f4f4;
  padding: 0.3rem 0.5rem;
  border-radius: 4px;
  font-family: monospace;
}

footer {
  background-color: #2b71b7;
  color: #fff;
  text-align: center;
  padding: 1.5rem;
  font-size: 1rem;
  margin-top: 2rem;
}

footer p {
  margin: 0;
}

  </style>
</head>
<body>

  <header>
    <h1>Robotic Arm for Object Sorting Based on Colour and Shape</h1>
    <p>Project Report</p>
    
  </header>

  <nav>
    <button onclick="location.href='#abstract'">Abstract</button>
    <button onclick="location.href='#toc'">Table of Contents</button>
    <button onclick="location.href='#intro'">Introduction</button>
    <button onclick="location.href='#literature'">Literature Review</button>
    <button onclick="location.href='#methodology'">Methodology</button>
    <button onclick="location.href='#results'">Results</button>
    <button onclick="location.href='#demo'">Demo</button>
    <button onclick="location.href='#conclusion'">Conclusion</button>
    <button onclick="location.href='#references'">References</button>
  </nav>

  <main>
    <section id="abstract">
        <h2>1. Abstract</h2>
        <p>This project focuses on the simulation and control of a compact industrial robotic arm (ABB IRB 140) for pick-and-place operations. The goal is to develop an automated system capable of sorting objects based on color and shape using a vision-based method. The robotic arm's movements are controlled through a series of algorithms designed to process image data and make decisions based on object classification. MATLAB's image processing techniques and CoppeliaSim's simulation environment are integrated to enable real-time object recognition, classification, and robotic manipulation in a virtual environment.The project demonstrates how combining these technologies can lead to a practical, cost-effective solution for automating sorting tasks in industrial applications. By utilizing the power of simulation, the system is tested without the need for physical hardware, ensuring a more flexible and scalable approach to robotic automation. This project aims to explore the integration of computer vision and robotics, highlighting the potential for efficient object sorting systems in manufacturing and production environments.</p>
    </section>



    <section id="toc">
      <h2>2. Table of Contents</h2>
      <p>
        1. Abstract<br>
        2. Table of Contents<br>
        3. Introduction<br>
        4. Literature Review / Related Work<br>
        5. Methodology & Implementation<br>
        6. Results and Discussion<br>
        7. Demo of Simulation and/or Hardware<br>
        8. Conclusion and Future Work<br>
        9. References
      </p>
    </section>

    <section id="intro">
        <h2>3. Introduction</h2>
        <p>Industrial robots have revolutionized manufacturing and automation processes, bringing about significant improvements in efficiency, precision, and versatility. These robots are used in a wide range of industries, including automotive, electronics, food processing, and packaging, to perform tasks such as assembly, welding, painting, and material handling. The use of robotic systems has enabled businesses to achieve higher production rates, reduce human error, and lower operational costs.
           This project focuses on developing a robotic arm simulation that can sort objects based on two critical attributes: color and shape. The goal is to design and implement a system that utilizes computer vision and robotic control to detect the features of objects and automatically perform sorting operations with high accuracy and reliability.</p>
    
        <p>The project leverages MATLAB’s powerful image processing techniques for preprocessing and feature extraction. MATLAB enables the system to analyze visual data, classify objects based on their color and shape, and prepare the data for further processing. The system employs various image processing techniques such as color filtering, shape recognition, and edge detection to identify and classify objects accurately.
         In addition to MATLAB, this project uses the CoppeliaSim simulation environment (formerly V-REP), which provides a flexible platform for simulating robotic arms and their interactions with objects. CoppeliaSim allows for the creation of realistic 3D simulations of robotic systems, providing a virtual testing ground for the robotic arm’s performance. The robotic arm’s movements are controlled through inverse kinematics and other algorithms to perform pick-and-place operations efficiently and accurately.The system operates by capturing real-time images of the environment, analyzing the features of the objects, and then instructing the robotic arm to pick up and place the objects in designated locations based on the classification. This approach enables the simulation of object sorting tasks without the need for physical hardware, making it an ideal solution for testing and prototyping robotic systems in a virtual environment.
         The primary objective of this project is to demonstrate the integration of computer vision and robotics for automated sorting, highlighting the potential of such systems in industries requiring high precision and efficiency. The successful development of this system will showcase the power of MATLAB and CoppeliaSim in creating a versatile and effective robotic sorting solution.</p>
    </section>
    
    <section id="literature">
        <h2>4. Literature Review / Related Work</h2>
        <table>
          <thead>
            <tr>
              <th>S. No</th>
              <th>Paper</th>
              <th>Author</th>
              <th>Year</th>
              <th>Key Findings</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>1</td>
              <td>Detection & Distinction of Colors using Color Sorting Robotic Arm in a Pick & Place Mechanism</td>
              <td>Uzma Amin, Ghulam Ahmad, Nudrat Liaqat, Manzar Ahmed, Sumbal Zahoor</td>
              <td>2012</td>
              <td>Accurate, low-cost color sorting using a PIC microcontroller and TCS3200 sensor with 360° arm rotation and 1kg payload capacity.</td>
            </tr>
            <tr>
              <td>2</td>
              <td>Object Sorting Robot Based On the Shape</td>
              <td>Priya Vinayak</td>
              <td>2017</td>
              <td>Image processing in MATLAB with an ARM7-controlled robotic arm enables fully automated and efficient object sorting based on shape.</td>
            </tr>
            <tr>
              <td>3</td>
              <td>Robotic Arm Control Based on Internet of Things</td>
              <td>Shuangquan Fu, Pritesh Chandrashekhar Bhavsar</td>
              <td>2019</td>
              <td>Integrates IoT technologies like MQTT protocol to enable accurate, real-time, platform-independent remote control of a 6-DOF robotic arm via a web interface.</td>
            </tr>
            <tr>
              <td>4</td>
              <td>Identification and Sorting of Objects based on Shape using robotic arm</td>
              <td>B.R. Shivakumar, Lennon Fernandes</td>
              <td>2020</td>
              <td>Integrates real-time image processing with robotic control to accurately detect and sort objects based on their 2D shape.</td>
            </tr>
            <tr>
              <td>5</td>
              <td>Object Grabbing of Robotic Arm Based on OpenMV Module Positioning</td>
              <td>Jian Wang, Haishen Peng</td>
              <td>2023</td>
              <td>Integrating machine vision with inverse kinematics enables a robotic arm to autonomously recognize and grasp a target object.</td>
            </tr>
          </tbody>
        </table>
      </section>
      
      

   
        <section id="implementation">
          <h2>4. Implementation</h2>
      
          <h3>Robotic Arm</h3>
          <p><strong>Type:</strong> 6 Degrees of Freedom (6-DOF) Industrial Robot</p>
          <p><strong>Model:</strong> ABB IRB140</p>
          <p><strong>Environment:</strong> Simulated in CoppeliaSim</p>
          <p><strong>Control:</strong> Lua scripting with simIK API for motion control</p>
      
          <p>Random objects are generated during the simulation using Lua scripting. Each object is assigned a random shape (cube, cuboid, or cylinder) and a random color (red, green, or blue). Objects are created using <code>sim.createPureShape()</code> with specified size and mass parameters. All objects are spawned directly on the conveyor belt at a fixed position. Objects are dynamic, collidable, and detectable, allowing them to interact with the conveyor and sensors.</p>
      
          <h3>Object Generation and Classification</h3>
          <p><strong>Color and Shape Classification:</strong></p>
          <ul>
            <li>Convert RGB image to HSV (Hue, Saturation, Value).</li>
            <li>Use thresholds on Hue, Saturation, and Value to isolate object pixels.</li>
            <li>Classify color based on average Hue value:
              <ul>
                <li>Red: Hue < 0.05 or > 0.95</li>
                <li>Green: Hue ~ 0.3–0.45</li>
                <li>Blue: Hue ~ 0.55–0.7</li>
              </ul>
            </li>
          </ul>
      
          <h4>Sobel and Laplacian Filters for Edge Detection</h4>
          <p><strong>Sobel Operator:</strong> Detects edges by calculating the gradient (change in intensity) in both horizontal and vertical directions. It uses Sobel filters (kernels) to approximate the first derivative and highlights regions with rapid intensity change, typically the boundaries of objects.</p>
          <p><strong>Formula for Gradient in X and Y directions:</strong></p>
          <pre>
            G_x = [ -1  0  1
                    -2  0  2
                    -1  0  1 ]
      
            G_y = [ -1 -2 -1
                     0  0  0
                     1  2  1 ]
          </pre>
          <p>The <strong>Gradient Magnitude</strong> is calculated as:</p>
          <pre>
            Gradient Magnitude = sqrt(G_x^2 + G_y^2)
          </pre>
      
          <p><strong>Laplacian Filter:</strong> This filter detects edges by finding second-order derivatives in the image. It is more sensitive to noise but can detect finer details and subtle edges in the image.</p>
          <pre>
            Laplacian = ∇² I(x, y)
          </pre>
      
          <h3>A* Algorithm for Path Planning</h3>
          <p>A* is a graph-based search algorithm used to find the shortest path between two points using a heuristic function. The heuristic function h(n) is the Manhattan distance to the goal, and the cost function g(n) represents the cost from the start to node n.</p>
          <p>The total cost function is:</p>
          <pre>
            f(n) = g(n) + h(n)
          </pre>
          <p>Using the A* algorithm, the robot follows the generated waypoints step-by-step, guided by inverse kinematics for smooth and accurate motion.</p>
      
          <h3>Inverse Kinematics</h3>
          <p>Inverse Kinematics is used to calculate the joint angles required for the robot’s end effector to reach a target position and orientation in 3D space. The mathematical formulation for inverse kinematics is:</p>
          <pre>
            θ = J⁺ * x
          </pre>
          <p>where θ represents the joint angles, J⁺ is the pseudo-inverse of the Jacobian matrix, and x is the desired end-effector velocity. The pseudo-inverse of the Jacobian matrix is calculated using the following equation:</p>
          <pre>
            θ = J⁺ * Δx
          </pre>
          <p>This enables precise movements of the robot during object pickup and bin placement tasks.</p>
      
          <h3>Forward Kinematics</h3>
          <p>Forward Kinematics calculates the position and orientation of the robot's end effector from its joint angles. The general equation for Forward Kinematics is:</p>
          <pre>
            T = ∏(T_i(θ_i))
          </pre>
          <p>where T is the transformation matrix of the end effector, and T_i(θ_i) is the transformation matrix for each joint i, based on the joint angles θ_i. This calculation is automatically handled in CoppeliaSim whenever joint angles are updated or inverse kinematics is solved.</p>
      
          <h3>Implementation in CoppeliaSim</h3>
              <p>In this simulation, a robotic arm in CoppeliaSim is tasked with detecting, identifying, and sorting randomly generated objects of various shapes—cubes, cuboids, and cylinders—and colors—red, green, and blue. The simulation begins with the automatic generation of these objects on a conveyor belt, each having a random combination of shape and color. A MATLAB script is used to connect to CoppeliaSim via a remote API. When the object reaches the vision sensor in the simulation, an image is captured and sent to MATLAB.</p>
          
              <p>Inside MATLAB, image processing techniques are applied to extract object features. The edges of the objects are detected using both Sobel and Laplacian operators, which help enhance the structural outlines of different shapes. The Sobel operator detects edges by calculating the gradient in both horizontal and vertical directions, while the Laplacian operator detects finer edges by finding second-order derivatives in the image. These edge detection methods allow the software to distinguish and enhance the boundaries of objects in the image.</p>
          
              <p>From the processed image, the shape (cube, cuboid, cylinder) and color (red, green, blue) of the object are identified and displayed in a MATLAB figure, visually labeling the object. This image processing step helps accurately classify the object based on its features, which are then passed to the robotic arm.</p>
          
              <p>Based on this classification, the object is directed toward the appropriate bin. The robot uses <strong>Inverse Kinematics (IK)</strong> to move its end-effector from the current position to the target position above the correct bin. IK is used to calculate the joint angles needed to position the arm's end-effector at the desired location.</p>
          
              <p>To optimize the robot's movement, the <strong>A*</strong> algorithm is implemented for path planning. A* is a graph-based search algorithm that computes the most efficient path from the robot's current position to the target bin by considering both the distance and any obstacles in the environment. The robot follows the calculated waypoints, adjusting its motion using inverse kinematics to reach the destination smoothly and efficiently.</p>
              </section>
              <head>
  <style>
    .center-img {
      display: block;
      margin-left: auto;
      margin-right: auto;
    }
    .caption {
      text-align: center;
      font-style: italic;
      margin-top: 5px;
      margin-bottom: 15px;
    }
  </style>
</head>

<section id="results">
  <h2>6. Results and Discussion</h2>
  <p>The results of the simulation and hardware implementation of the robotic arm for object sorting based on color and shape were analyzed. The system was able to accurately classify objects in real-time using the vision-based method. The MATLAB image processing techniques and CoppeliaSim’s simulation environment performed efficiently, demonstrating high accuracy in sorting tasks. The robot successfully picked and placed objects based on color (red, green, blue) and shape (cube, cuboid, cylinder) with minimal errors. However, challenges were encountered in real-time object recognition under varying lighting conditions, which led to occasional misclassification. Future work should focus on optimizing the system's performance under different environmental factors.</p>
  
  <img src="intial.jpg" alt="Robotic Arm for Object Sorting" width="400" class="center-img" />
  <p class="caption">Figure 1: Simulation setup</p>

  <p>The robotic arm is ready to sort and place an object into one of the three colored bins (red, green, or blue) based on its color. The vision sensor monitors objects on the conveyor belt.</p>
  
  <img src="2.jpg" alt="Robotic Arm for Object Sorting" width="400" class="center-img" />
  <p class="caption">Figure 2: Object detection</p>
  
  <p>The robotic arm has detected a red square object using the vision sensor. It picks it up from the conveyor belt for sorting into the appropriate bin based on its color.</p>
  
  <img src="3.jpg" alt="Robotic Arm for Object Sorting" width="400" class="center-img" />
  <p class="caption">Figure 3: Object sorting</p>
  
  <p>The robotic arm successfully detects and places the red cylindrical object into the corresponding red bin based on its color.</p>
  
  <img src="4.png" alt="Robotic Arm for Object Sorting" width="400" class="center-img" />
  <p class="caption">Figure 4: Edge-detection of cuboid</p>
  
  <p>The system successfully detects and classifies a green cuboid using contour analysis and color filtering in MATLAB, confirming both color and shape recognition. The edge-detected image highlights the clear boundaries of the object, enabling accurate shape approximation using Sobel and Laplacian.</p>
  
  <img src="5.png" alt="Robotic Arm for Object Sorting" width="400" class="center-img" />
  <p class="caption">Figure 5: Edge-detection of cylinder</p>
  
  <p>The system successfully detects and classifies a red cylinder using contour analysis and color filtering in MATLAB, confirming both color and shape recognition. The edge-detected image highlights the clear boundaries of the object, enabling accurate shape approximation using Sobel and Laplacian.</p>
</section>

          
              <section id="demo">
                <h2>7. Demo of Simulation</h2>
              
                <!-- Video Player -->
                <video width="640" height="360" controls>
                  <source src="video.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
              
                <p>
                  A live demo of the simulation was conducted, showcasing the robotic arm performing pick-and-place operations with objects classified by color and shape. The simulation was run in CoppeliaSim, where the arm successfully identified and sorted objects based on the image data processed in MATLAB. The robot's movements were controlled using inverse kinematics algorithms, ensuring precise placement of objects. In addition, a hardware demonstration was performed on a physical robotic arm, highlighting the system's potential in real-world applications. The demo provided a practical understanding of how the robotic arm can be integrated into a production environment for automated sorting tasks.
                </p>
              </section>
              
          <section id="future-scope">
            <h2>Future Scope</h2>
            <p>The developed robotic arm system for object sorting based on color and shape has promising potential for future enhancements and applications. Several areas can be explored to improve the system's performance, versatility, and scalability. Below are some key directions for future work:</p>
          
            <h3>1. Enhanced Object Recognition Under Variable Conditions</h3>
            <ul>
              <li><strong>Lighting Variability:</strong> The current system faces challenges with object misclassification under different lighting conditions. Future work could focus on improving image processing techniques to account for changing light sources. Techniques such as adaptive thresholding, dynamic lighting compensation, or integrating machine learning-based recognition algorithms could help mitigate lighting issues.</li>
              <li><strong>Complex Backgrounds:</strong> In real-world environments, objects may not always be placed on a uniform or simple background. Future systems could incorporate advanced segmentation techniques or background subtraction methods to improve the accuracy of object recognition in complex environments.</li>
            </ul>
          
            <h3>2. Integration of Machine Learning and AI</h3>
            <ul>
              <li><strong>Deep Learning for Object Detection:</strong> Incorporating Convolutional Neural Networks (CNNs) or other deep learning models could significantly enhance the object recognition capability of the system. These models can be trained to detect objects based on both color and shape in diverse environments, thus improving accuracy and reliability.</li>
              <li><strong>Reinforcement Learning for Robotic Movement:</strong> Implementing reinforcement learning (RL) can enable the robotic arm to learn from its environment and optimize its movement for better efficiency, minimizing the time taken for sorting and enhancing precision.</li>
            </ul>
          
            <h3>3. Real-Time Performance Improvements</h3>
            <ul>
              <li><strong>Faster Processing Algorithms:</strong> While the system works well under controlled conditions, real-time processing can be optimized further. Techniques such as parallel processing, optimized image processing algorithms, and the use of GPUs could be implemented to reduce processing time and improve response time for real-time sorting tasks.</li>
              <li><strong>Hardware Upgrades:</strong> Moving from a simulation environment to real-world implementation may require adjustments to the hardware, such as the use of higher precision sensors and more powerful processors. Upgrading to industrial-grade robotic arms with higher load capacities and faster actuation could enhance the scalability and utility of the system.</li>
            </ul>
          
            <h3>4. Multi-Object Sorting and Classification</h3>
            <ul>
              <li><strong>Sorting Multiple Objects Simultaneously:</strong> The current system works with individual objects, but in an industrial setting, multiple objects may need to be sorted simultaneously. Future work could explore algorithms for identifying and classifying multiple objects within the same scene and implementing simultaneous pick-and-place operations.</li>
              <li><strong>Sorting Based on Additional Criteria:</strong> Beyond color and shape, additional object properties such as size, texture, or material type could be incorporated into the classification system. This would allow for more complex sorting tasks, such as sorting fragile objects, hazardous materials, or products with varying physical characteristics.</li>
            </ul>
          
            <h3>5. Autonomous Adaptation to New Objects</h3>
            <ul>
              <li><strong>Adaptive Object Recognition:</strong> The system could be designed to learn and adapt to new objects dynamically, without requiring manual reprogramming. This would involve developing algorithms for continuous learning and training on new object categories and shapes.</li>
              <li><strong>Self-Calibration:</strong> In the future, the system could be made more autonomous by incorporating self-calibration techniques, enabling it to automatically adjust its settings or compensate for mechanical wear and tear, ensuring consistent performance over time.</li>
            </ul>
          
            <h3>6. Integration with Industrial IoT (Internet of Things)</h3>
            <ul>
              <li><strong>Smart Factory Integration:</strong> The robotic arm could be integrated with industrial IoT systems to enable real-time monitoring and control. This would allow for data-driven insights, such as performance tracking, predictive maintenance, and efficient resource management. Furthermore, the system could be connected to a cloud platform to facilitate remote monitoring and control.</li>
              <li><strong>Collaboration with Other Robots:</strong> In a fully automated manufacturing environment, multiple robotic arms could work together to perform sorting tasks in a collaborative manner. Future work could explore multi-robot systems that communicate and coordinate with each other to increase overall throughput.</li>
            </ul>
          
            <h3>7. Cost Reduction and Scalability</h3>
            <ul>
              <li><strong>Affordable Hardware for Mass Adoption:</strong> To make the system accessible for smaller businesses and industries, cost reduction strategies could be implemented. This includes using affordable vision systems, more cost-effective robotic arms, and open-source software solutions to keep the costs low without compromising performance.</li>
              <li><strong>Scalability for Larger Operations:</strong> The system could be scaled for large-scale operations, such as automated warehouses, logistics centers, or recycling plants. Future developments could focus on creating a modular system that can be easily expanded to meet the needs of large-scale sorting tasks.</li>
            </ul>
          
            <h3>8. Improved User Interface and System Control</h3>
            <ul>
              <li><strong>Intuitive Control Systems:</strong> The future system could include a more user-friendly interface, allowing operators to easily set sorting criteria, monitor system performance, and make adjustments in real time. This could involve integrating touchscreen displays, voice commands, or even AI-powered assistants for efficient control.</li>
              <li><strong>Automation of System Tuning:</strong> For environments with variable conditions, future systems could be designed to automatically tune the system parameters (such as object recognition sensitivity, arm speed, etc.) based on the conditions in real-time, reducing the need for manual calibration.</li>
            </ul>
          </section>
          
          <section id="conclusion">
              <h2>8. Conclusion</h2>
              <p>In this project, a simulated robotic arm system was developed for sorting objects based on their color and shape, leveraging advanced image processing techniques and robotic simulation tools. The primary goal was to create a reliable and efficient system that can accurately identify and manipulate objects, with applications in automated sorting for industrial purposes.

                To achieve this, MATLAB was utilized for processing visual data obtained from the environment. The image processing techniques in MATLAB, such as color-based segmentation and shape detection, were crucial in ensuring the accuracy of object classification. These techniques were further integrated with CoppeliaSim, a powerful robotic simulation platform, which allowed for the realistic simulation of robotic arm movement and sorting actions.
                
                Through careful design and testing, the system was able to perform accurate pick-and-place operations based on the color (red, green, blue) and shape (cube, cuboid, cylinder) of the objects. This involved detecting the position and orientation of the objects in real-time and sending commands to the robotic arm for precise object manipulation. The system demonstrated high accuracy in sorting tasks, with minimal errors during execution, making it an effective solution for industrial applications requiring automated sorting.
                
                However, challenges were encountered in achieving consistent real-time object recognition under varying lighting conditions. In such scenarios, occasional misclassifications were observed. This indicates the need for further optimization in image processing algorithms to handle different environmental factors more robustly, such as adjusting for lighting changes or implementing more advanced object recognition methods.
                
                Overall, the project successfully demonstrated a working model of a robotic arm system that could be applied in industrial settings for automated sorting. With further refinements, such as improvements in real-time recognition under varying conditions and enhanced robustness of the image processing pipeline, this system holds the potential to become a fully functional, reliable solution for automated object sorting in various industries, including manufacturing, packaging, and logistics. The integration of MATLAB and CoppeliaSim provides a strong foundation for future expansions and real-world implementation, making it a valuable contribution to the field of robotics and automation.</p>
          </section>
          
          <section id="references">
            <h2>References</h2>
            <ul>
              <li>
                <strong>Detection & Distinction of Colors using Color Sorting Robotic Arm in a Pick & Place Mechanism</strong><br>
                Author: Uzma Amin, Ghulam Ahmad, Nudrat Liaqat, Manzar Ahmed, Sumbal Zahoor<br>
                Year: 2012<br>
                <a href="https://tinyurl.com/2p8avwh5" target="_blank">
                  https://tinyurl.com/2p8avwh5
                </a>
                
                
                </a>
              </li>
              <li>
                <strong>Object Sorting Robot Based On the Shape</strong><br>
                Author: Priya Vinayak<br>
                Year: 2017<br>
                <a href="https://d1wqtxts1xzle7.cloudfront.net/55559433/Object_Sorting_Robot_Based_on_Shape-libre.pdf" target="_blank">
                  d1wqtxts1xzle7.cloudfront.net/.../Object_Sorting_Robot_Based_on_Shape.pdf
                </a>
                
              </li>
              <li>
                <strong>Robotic Arm Control Based on Internet of Things</strong><br>
                Author: Shuangquan Fu, Pritesh Chandrashekhar Bhavsar<br>
                Year: 2019<br>
                <a href="https://ieeexplore.ieee.org/abstract/document/8817333" target="_blank">
                  https://ieeexplore.ieee.org/abstract/document/8817333
                </a>
              </li>
              <li>
                <strong>Identification and Sorting of Objects based on Shape using robotic arm</strong><br>
                Author: B.R. Shivakumar, Lennon Fernandes<br>
                Year: 2020<br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9171196" target="_blank">
                  https://ieeexplore.ieee.org/abstract/document/9171196
                </a>
              </li>
              <li>
                <strong>Object Grabbing of Robotic Arm Based on OpenMV Module Positioning</strong><br>
                Author: Jian Wang, Haishen Peng<br>
                Year: 2023<br>
                <a href="https://ieeexplore.ieee.org/abstract/document/10277796" target="_blank">
                  https://ieeexplore.ieee.org/abstract/document/10277796
                </a>
              </li>
              <li>
                <p><strong>Exploring Vision-based Robotic Arm Control with 6 Degrees of Freedom</strong></p>
                <ul>
                  <li><a href="https://encord.com/blog/robotic-arm-with-6-degrees-of-freedom-using-computer-vision/" target="_blank">
                    https://encord.com/blog/robotic-arm-with-6-degrees-of-freedom-using-computer-vision/
                  </a></li>
                  <li><a href="https://scienpg.com/jea/index.php/jea/article/view/jea.2020.04.002" target="_blank">
                    https://scienpg.com/jea/index.php/jea/article/view/jea.2020.04.002
                  </a></li>
                </ul>
              </li>
              <li>
                <p><strong>Computer Vision Based Industrial Robotic Arm for Sorting Objects by Color and Height</strong></p>
                <ul>
                  <li>
                    CoppeliaSim pick and place tutorial: 
                    <a href="https://youtu.be/9X8QVcuJvQ4?si=iVbvZgTBVzqxNUYg" target="_blank">
                      https://youtu.be/9X8QVcuJvQ4?si=iVbvZgTBVzqxNUYg
                    </a>
                  </li>
                </ul>
              </li>
            </ul>
          </section>
          
          
    <!-- Other sections (Results, Demo, Conclusion, References) remain unchanged -->

  </main>

  <footer>
    &copy; 2025 Robotic Arm Project Team 1| A
  </footer>

</body>
</html>
